from langchain_core.messages import SystemMessage, HumanMessage
from langchain_core.language_models.chat_models import BaseChatModel
from langgraph.graph import StateGraph, START, END
from typing import List, TypedDict
from pydantic import BaseModel, Field


class Task(BaseModel):
    title: str = Field(
        description="Descriptive title for this specific security assessment task \
            (e.g., 'Directory Enumeration', 'Authentication Testing', 'Input Validation Analysis')",
    )
    instructions: str = Field(
        description="Detailed instructions that guide the bug bounty hunter agent on how to \
            execute this specific task, including objectives, methodologies, tools to use, \
            success criteria, and expected deliverables. Please include all relevant information \
            needed to execute the task from the reconnaissance phase onward.",
    )


class Plan(BaseModel):
    tasks: List[Task] = Field(
        description="List of tasks to be executed during the bug bounty engagement",
    )


class State(TypedDict):
    base_url: str
    reconnaissance: str
    plan: List[Task]


SYSTEM_PROMPT = """
You are a planning assistant for an authorized bug-bounty team. 
The reconnaissance phase has already been completed and the reconnaissance report 
will be provided as input. Use only information from that reconnaissance report 
(do not perform or suggest any further reconnaissance).

You will generate a prioritized set of test tasks aimed at discovering vulnerabilities
on the target website. Tasks must be actionable for a security tester but must not contain
step-by-step exploit scripts or instructions that would enable malicious actors. 
Keep guidance high-level and focused on objectives, prerequisites and expected observations.

Scope (what to cover)

- Authentication & credential handling ‚Äî password reset, account enumeration, MFA, leaked creds.
- Session management ‚Äî session fixation, expiry, Secure/HttpOnly/SameSite, rotation on privilege change.
- Broken access control / authorization ‚Äî horizontal/vertical privilege escalation, IDORs.
- Input validation & injection families ‚Äî SQLi, NoSQL/LDAP, command/OS injection, template injection.
- Cross-Site Scripting (XSS) ‚Äî reflected, stored, DOM contexts (HTML, attribute, JS, URL).
- Cross-Site Request Forgery (CSRF) ‚Äî state-changing endpoints without anti-CSRF tokens, SameSite issues.
- Clickjacking / UI redress ‚Äî missing X-Frame-Options / CSP frame-ancestors on sensitive pages.
- CORS / cross-origin misconfiguration ‚Äî overly permissive origins, credentials with wildcard.
- Insecure direct object references (IDOR) ‚Äî predictable IDs, missing server-side checks.
- File upload & parsing ‚Äî MIME/type checks, executable uploads, image processing vulnerabilities.
- Server-Side Request Forgery (SSRF) ‚Äî URL fetchers, open-redirect-supported fetches, metadata endpoints.
- Open redirect / URL handling ‚Äî unvalidated redirect parameters, canonicalization issues.
- Security headers & TLS config ‚Äî HSTS, CSP, Referrer-Policy, TLS versions/ciphers.
- Directory Traversal and Information Disclosure Testing
- Token-based auth & JWT issues ‚Äî signing, alg none, audience/issuer checks, token lifetime.
- API-specific checks (REST / GraphQL / WebSockets) ‚Äî object-level auth, introspection, WebSocket auth.
- Rate limiting & brute-force protections ‚Äî account lockout, IP throttling, CAPTCHA.
- Business-logic & workflow abuse ‚Äî order manipulation, refunds, race conditions.
- Data exposure & privacy ‚Äî sensitive data in responses, verbose errors, backups.
- Dependency & component vulnerabilities ‚Äî outdated libs, known CVEs.
- Insecure deserialization & object tampering ‚Äî client-accepted serialized objects.
- XML-related risks (XXE) ‚Äî XML parsers, SOAP endpoints.
- Client-side storage & secrets ‚Äî tokens in localStorage, API keys in JS.

Also include any additional relevant test areas suggested by the reconnaissance report.

"""


def create_planning_graph(llm: BaseChatModel):
    def plan(state: State):
        print(f"üõ†Ô∏è Planning ...")
        response = llm.with_structured_output(Plan).invoke(
            [
                SystemMessage(content=(SYSTEM_PROMPT)),
                HumanMessage(
                    content=f"The reconnaissance report is: {state['reconnaissance']}"
                ),
                HumanMessage(content=f"The target website is {state['base_url']}."),
            ]
        )

        return {"plan": response.tasks}

    graph_builder = StateGraph(State)
    graph_builder.add_node("plan", plan)

    graph_builder.add_edge(START, "plan")
    graph_builder.add_edge("plan", END)

    result = graph_builder.compile()
    print(result.get_graph().draw_mermaid())
    return result
